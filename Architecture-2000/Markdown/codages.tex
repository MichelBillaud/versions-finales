Codages de l'information
========================

Les ordinateurs manipulent les informations sous forme *binaire* :
toutes les données sont représentées par des suites d'éléments
d'information (*bits*) qui ne peuvent prendre que deux valeurs, appelées
arbitrairement $0$ et $1$ (ou *vrai* et *faux*).

On remarque qu'une séquence de 2 bits peut prendre 4 valeurs différentes
$00, 01, 10, 11$. Une séquence de 3 bits peut prendre 8 valeurs: $000$,
$001$,$010$,$011$,$100$,$101$,$110$,$111$. Plus généralement, il y a
$2^n$ séquences de $n$ bits.

> **Exercice** Combien faut-il de bits d'information pour désigner une
> carte parmi les 78 d'un jeu de tarot ?

Le codage choisi dépendra de la nature des informations à coder
(caractères, nombres entiers ou pas, positifs ou pas etc.) et les
traitements que l'on désire effectuer sur ces informations.

Bases de numération
-------------------

### La notation positionnelle

Dans la vie courante nous utilisons le *système décimal positionnel*
pour représenter les nombres ; *décimal* parce qu'il emploie dix
symboles (les chiffres 0 à 9), *positionnel* parce que la valeur que
l'on attache à ces chiffres dépend de leur position dans le nombre.

> **Exemple** Dans $4305,72$ nous accordons au 4 une valeur de milliers,
> au 3 des centaines, etc. La valeur de ce nombre se lit donc:
> $$(4 \times 1000) + (3 \times 100) + (0 \times 10) + (5 \times 1) + 
> (7 \time 1/10) + (2 \times 1/100)$$ ou encore
> $$4 \times 10^3 + 3 \times 10^2 + 0 \times 10^1 + 5 \times 10^0 + 
> 7 \times 10^{-1} + 2 \times 10^{-2}$$

Ce système positionnel est utilisable avec d'autres bases de numération.
Les informaticiens emploient fréquemment les systèmes suivants:

-   *binaire*, ou base 2, qui utilise seulement deux chiffres 0 et 1,

-   *octal*, ou base 8, (chiffres 0 à 7)

-   *hexadécimal*, ou base 16, qui emploie les chiffres $0$ à $9$, puis
    les lettres A (qui représente la valeur $10$), B=11, ...F=15

Lorsqu'il y a risque de confusion, on fait figurer la base de numération
en indice ou entre parenthèses après le nombre concerné.

Le principe commun de toutes ces bases est le suivant: un nombre $N$
écrit en base $B$ est représenté par une suite de chiffres adjacents
$x_n x_{n-1} \ldots x_1 x_0$. Chacun de ces chiffres est un symbole qui
a une valeur entière comprise entre 0 et $B-1$. A chaque position est
attribué un poids qui est une puissance de $B$. Le chiffre le plus à
droite a un poids de $1 = B^0$, son voisin de $B=B^1$, le suivant de
$B^2$ etc. La valeur du nombre $N$ s'obtient en faisant la somme des
produits des valeurs des chiffres par leur poids respectifs:
$$N = x_n \times B^N + x_{n-1} \times B^{n-1} +  \ldots + x_1 \times B^1
+ x_0 \times B^0$$

> **Exemple Expression décimale de $421(8)$**
> $$4 \times 8^2 + 2 \times 8^1 + 1 \times 8^0 
> = 4 \times 64 + 2 \times 8 + 1 = \ldots (10)$$

Ceci se généralise facilement aux nombres "à virgule": les chiffres de
la "partie décimale" ont alors des poids successifs de
$B^{-1} = 1/B, B^{-2} = 1/{B^2}, \ldots$.

### Conversion vers le système décimal

La méthode usuelle de conversion découle immédiatement de la définition
donnée plus haut.

> **Exemple Expression décimale de $N=1001011(2)$** On écrit de droite à
> gauche, sous chacun des chiffres de N, les puissances successives de
> 2. On multiplie ensuite chaque chiffre par son poids, et on fait la
> somme. 

$$\begin{array}{r|rrrrrrr|l}
N= &1 & 0 & 0 & 1 & 0 & 1 & 1 \\
\times poids &64 &32& 16& 8& 4 &2 &1 \\
\hline
= &64 & 0 & 0 & 8 & 0 & 2 & 1 & total =  75 (10)
\end{array}$$

~~~
 N =       1  0  0  1  0  1  1
 x poids  64 32 16  8  4  2  1 
 =        64        8     1  1  +  75 (10)
~~~

### De décimal vers base quelconque

#### Méthode des restes successifs

Diviser le nombre à convertir par la valeur de la base. Le reste de la
division fournit le chiffre de droite, et recommencer avec le quotient.
S'arrêter à 0.

> **Exemple Conversion de $1789 (10)$ en hexadécimal**
>
> -   $1789 = 111 \times 16 + 13$. On pose $x_0 = D$.
>
> -   $111 = 6 \times 16 + 15$. On pose $x_1 = F$.
>
> -   $6 = 0 \times 16 + 6$. On pose $x_2 = 6$.
>
> -   le résultat est $6FD (16)$
>
#### Méthode soustractive

Écrire une liste des puissances successives de la base, de droite à
gauche. Chercher le plus grand poids contenu dans le nombre. Diviser le
nombre par ce poids, écrire le quotient en dessous, et recommencer avec
le reste. On met des 0 dans les autres positions.

On utilise cette méthode surtout avec le système binaire puisque la
division ne nécessite en fait qu'une soustraction (le quotient est
forcément 1).

> **Exemple Conversion de $1789 (10)$ en binaire**
>
> La liste des poids est
> $$\ldots 2048, 1024, 512, 256, 128, 64, 32, 16, 8, 4, 2, 1$$
>
> -   Comme $2048 > 1789 \geq 1024$, on met 1 sous 1024, et on soustrait
>     ce poids $1789 -1024 = 765$
>
> -   Comme $1024 > 765 \geq 512$, on met 1 sous 512, et on soustrait ce
>     poids $765 - 512 = 253$
>
> -   on met 1 sous 128, et on soustrait $253-128 = 125$
>
> -   on met 1 sous 64, et on soustrait $125-64 = 61$
>
> -   on met 1 sous 32, et on soustrait $61-32 = 29$
>
> -   on met 1 sous 16, et on soustrait $29-16 = 13$
>
> -   on met 1 sous 8, et on soustrait $13-8 = 5$
>
> -   on met 1 sous 4, et on soustrait $5-4 = 1$
>
> -   on met 1 sous 1, et on arrête. Le résultat est
>     $110\ 1111\ 1101 (2)$.
>
### Conversions entre bases 2, 8 et 16

Les nombres 8 et 16 étant des puissances entières de 2, il existe un
moyen très rapide de convertir un nombre binaire en octal ou hexadécimal
(et réciproquement), puisqu'à chaque chiffre octal (resp. hexadécimal)
correspond une "tranche" de 3 (resp. 4) bits dans la représentation
binaire du nombre.

> **Exemple Conversion de $11011111101 (2)$ en octal et hexadécimal** On
> découpe le nombre en tranches de 3 bits (matérialisées ici par des
> espaces) en partant des unités. On obtient $11\ 011\ 111\ 101 (2)$. On
> lit ensuite ce nombre en traduisant chaque tranche par un chiffre
> octal, et on trouve $3375 (8)$.
>
> Si on découpe par tranches de 4 on obtient $110\ 1111\ 1101 (2)$, ce
> qui donne $6FD (16)$.

Le système hexadécimal permet de coder des séquences binaires de façon 4
fois plus courte, les conversions se faisant sans calcul.

Arithmétique binaire
--------------------

Les opérations arithmétiques usuelles peuvent se faire dans toutes les
bases, selon des procédés très proches de l'arithmétique décimale. Nous
ne présenterons ici que l'arithmétique et la multiplication binaire, les
autres opérations (ainsi que la généralisation à d'autres bases) est
laissée en exercice.

### Addition binaire

Comme il n'y a que deux chiffres, la table d'addition se réduit à peu de
choses

~~~
       0   1
	 +-------+
   0 | 0   1 |
   1 | 1  10 |
	 +-------+
~~~

Pour additionner deux nombres $A$ et $B$, on les écrit l'un sous
l'autre, et on commence l'addition par la droite. L'addition de deux
chiffres 1 engendre une retenue, que l'on propage au rang suivant.

> **Exemple Somme de 1011101 et 1110001** $$\begin{array}{rrrrrrrrrl}
> &1 & 1 & 1 &   &   &   & 1 &   & retenues \\
> &  & 1 & 0 & 1 & 1 & 1 & 0 & 1 & A \\
> +&  & 1 & 1 & 1 & 0 & 0 & 0 & 1 & B \\
> \hline
> = &1 & 1 & 0 & 0 & 1 & 1 & 1 & 0 & Somme
> \end{array}$$

### Multiplication binaire

> **Exemple Produit de 110011 et 1101** $$\begin{array}{rrrrrrrrrr}
>  & & & &1&1&0&1&1 \\
> \times & & & & &1&1&0&1 \\
> \hline
>  & & & &1&1&0&1&1 \\
>  & & &0&0&0&0&0& \\
>  & &1&1&0&1&1& & \\
>  &1&1&0&1&1& \\
> \hline
> 1&0&1&0&1&1&1&1&1
> \end{array}$$

A chaque étape, les multiplications partielles par chacun des chiffres
du second nombre se ramènent soit à recopier le premier nombre avec un
décalage, soit à inscrire des 0.

Codages des nombres entiers en binaire
--------------------------------------

Le problème est de coder des nombres avec une séquence binaire de
longueur limitée. On sait déjà qu'avec un nombre fini de bits, on ne
pourra représenter qu'un nombre fini de valeurs ($2^N$, où $N$ est le
nombre de bits).

### Binaire pur

Si les nombres à représenter sont toujours positifs ou nuls, on pourra
adopter le codage *binaire pur non-signé*, qui est une application
directe de la numération binaire vue ci-dessus.

Sur un octet (8 bits) on écrira un nombre qui sera forcement compris
entre 0 et $2^8-1 =  255$.

> **Exemple** Le nombre $35 (10)$ sera codé par $0010\ 0011$. Le plus
> grand nombre représentable (ici 255) sera traduit par une suite de 1:
> $1111\ 1111$.

> **Exercice** Quels nombres peut on coder sur 16 bits ? Sur 32 bits ?

### Binaire signé

Si l'on veut représenter des nombres positifs ou négatifs, la première
idée qui vient est de réserver un bit (par exemple celui de gauche) pour
le signe, (0 pour positif, 1 pour négatif) et de coder la valeur absolue
du nombre sur les bits restants.

> **Exemple** Sur 8 bits, $+35 (10)$ sera codé par $0010\ 0011$, et
> $-35 (10)$ par $1010\ 0011$.

Quoique simple, ce procédé de codage n'est quasiment pas utilisé, car il
ne permet pas de faire facilement des opérations sur les nombres ainsi
codés (pour additionner deux nombres il faut examiner leurs signes puis
additionner les valeurs absolues, ou soustraire la plus petite de la
plus grande).

En outre, dans ce système le nombre 0 possède deux codages ($+0$ et
$-0$). On ne code donc que $2^N-1$ nombres distincts (de $-(2^{N-1}-1)$
à $+2^{N-1}-1)$.

### Représentation biaisée

L'idée est de décaler les entiers de l'intervalle choisi en leur
soustrayant la plus petite valeur de cet intervalle. Cela permet de se
ramener au codage des nombres positifs ou nuls.

> **Exemple** On choisit de coder l'intervalle $-127\ldots+128$. Le
> codage du nombre $-94$ s'obtient en lui ajoutant $127$, et en
> traduisant le résultat $-94+127=33$ en binaire, soit $0010\ 0001 (2)$.

Pour additionner deux nombres en représentation biaisée, il faudra
additionner leurs représentations biaisées, puis soustraire le biais.

> **Exercice** Détailler le calcul de $2+3$ en représentation biaisée
> sur 4 bits. Que faut-il faire pour une soustraction ?

### Binaire complément à deux

Ce procédé permet de coder, sur $N$ bits, les nombres de $-2^{N-1}$ à
$+2^{N-1}-1$:

-   les nombres positifs (de 0 à $+2^{N-1}-1$) sont écrits en binaire
    pur (on remarque que le bit de gauche sera alors forcément à 0)

-   aux nombres négatifs (entre $-2^{N-1}$ et $-1$), on ajoute $2^N$. Le
    nombre obtenu est alors écrit en binaire pur. Comme il est compris
    entre $2^{N-1}$ et $2^N-1$, son premier bit est à 1.

> **Exemple Codage de $-35$ sur un octet.** Le nombre à coder étant
> négatif, on lui ajoute $256$, et le problème se ramène donc à coder
> $256-35 = 221$ en binaire pur, soit $1101\ 1101$.

On le voit, ce codage est basé sur l'arithmétique modulo $2^N$. Puisque
les nombres -positifs ou négatifs- sont représentés par leurs valeurs
positives modulo $2^N$, l'addition et la soustraction se font sans se
préoccuper des signes : les circuits de calcul en seront grandement
simplifiés. C'est l'avantage décisif qui a conduit à l'adoption générale
de ce système.

Le dénomination de "complément à deux" provient de la remarque suivante:
pour calculer l'opposé d'un nombre ainsi codé, il suffit d'ajouter 1 à
son *complément à 1*, que l'on obtient en changeant les 1 en 0 et
réciproquement.

> **Exemple Codage de -35 par complémentation à deux.** En binaire pur
> $35 (10)$ s'écrit -sur un octet- $0010\ 0011$. Le complément à 1 est
> $1101\ 1100$. En ajoutant 1 on trouve $1101\ 1101$, qui est le codage
> attendu.

> **Remarque** Cette opération est idempotente: si on complémente
> $1101\ 1101$ on trouve $0010\ 0010$, et en ajoutant 1 on obtient
> $0010\ 0011$ qui est la représentation de $+35$. On utilise cette
> propriété pour le décodage: pour décoder un nombre écrit en binaire
> complément à deux
>
> -   si le premier bit est à 0, le signe est $+$, et la valeur absolue
>     est obtenue par un décodage binaire non signé du nombre ;
>
> -   si le premier bit est à 1, le signe est $-$, et la valeur absolue
>     s'obtient par décodage binaire non signé du complément à 2 de ce
>     nombre.
>
> **Exemple Décodage de $1111\ 0100$.** Le signe est négatif. Le
> complément à 2 est $0000\ 1011 + 1 = 0000\  1100$ qui, traduit en
> décimal vaut $12$. Le nombre cherché est donc $-12$.

Décimal Codé Binaire
--------------------

Cette notation hybride est utilisée pour le codage des grands nombres
entiers ou à virgule fixe dans les machines destinées aux applications
commerciales: chaque chiffre *décimal* est codé par une tranche de 4
bits.

> **Exemple Codage BCD de 14285739.** En mettant des espaces pour bien
> voir les tranches: $$0001\ 0100\ 0010\ 1000\ 0101\ 0111\ 0011\ 1001$$

Les procédés de codages et décodages entre décimal et BCD sont très
simples, et nous verrons que les circuits d'addition ne sont pas
beaucoup plus compliqués que dans le cas du binaire pur.

La représentation en virgule flottante
--------------------------------------

La représentation en virgule flottante permet de représenter des nombres
réels très petits et très grands, avec une bonne précision.

### La représentation flottante

L'idée de base est similaire à la notation des nombres sous la forme
d'une mantisse multipliée par une puissance de 10. Par exemple
$12.34 \times 10^{-30}$.

Cette notation est très employée en physique. Elle revient à décrire un
nombre par un couple $(m,e$) formé de la mantisse et de l'exposant, ici
$(12.34, -30)$. Il y a plusieurs couples qui représentent le même nombre
-par exemple $(1.234, -29), (1234, -32), \ldots$ - on peut donc convenir
d'une représentation *normalisée*, par exemple en décidant que
$1 \leq | m | < 10$. Tous les nombres (sauf 0) auront alors une
représentation unique.

En binaire, c'est la même idée : le nombre sera de la forme
$m \times 2^e$, avec $0 < | m | \leq 2$.

> **Exemple** Normaliser le nombre -13 en vue d'une représentation
> binaire.
>
> Comme 13 est compris entre $8=2^3$ et $16=2^4$, on prend $e=3$ et
> $m=-13/8= -1.625 (10) = -1.101 (2)$.

### Le format flottant standard IEEE

#### Représentations normalisées

Le format standard IEEE simple précision code les nombres réels sur 32
bits (soit 4 octets).

-   le premier bit S code le signe du nombre (0:positif, 1:négatif).

-   8 bits pour l'exposant (zone E). La représentation est biaisée:
    cette zone représente un nombre $e$ compris dans l'intervalle
    $-127..+128$, codé en binaire non signé avec un décalage de 127:
    $$e = E -127$$ Attention les "exposants" E=0 et E=127 sont réservés
    pour le codage de nombres "spéciaux" (voir plus loin).

-   23 bits pour la mantisse. Cette zone M ne contient que la partie
    décimale de la mantisse $m$, en effet la convention de normalisation
    nous assure que la partie entière est toujours 1. (Pour le codage
    du 0, voir plus loin).

> **Exemple** Coder $-13$ dans le format IEEE simple précision.
>
> On sait déjà que $-13 = -1.101 (2) \times 2^3$.
>
> -   Le nombre étant négatif, le signe S est 1.
>
> -   L'exposant est 3, on lui ajoute 127, et on obtient 130 qui, en
>     binaire sur 8 bits s'écrit $1000 0010$.
>
> -   La mantisse $1.101 (2)$ privée de sa partie entière est codée sur
>     23 bits: $101\ 0000\ 0000\ 0000\ 0000\ 0000$
>
> Le nombre réel -13 est donc codé en binaire:
> $$1100\ 0001\ 0101\ 0000\ 0000\ 0000\ 0000\ 0000$$ ou $C150 0000_H$,
> si on préfère l'hexadécimal (plus maniable).

> **Exercice** Décoder le nombre $1234 0000_H$.

> **Exercice** Quel est le plus grand nombre normalisé ? Le plus petit
> (en valeur absolue) ?

#### Les zéros, les infinis et les autres

Le nombre zéro est, par convention, représenté avec les zones E et M
remplies de zéros, le signe S étant indifférent (il y a donc deux zéros
...) : $$x000\ 0000\ 0000\ 0000\ 0000\ 0000\ 0000\ 0000$$

Les deux infinis $+\infty$ et $-\infty$ ont leur zone E remplies de 1,
et la zone M à 0: $$S111\ 1111\ 1000\ 0000\ 0000\ 0000\ 0000\ 0000$$

Certains codes spéciaux représentent des erreurs, on les appelle des NaN
(Not a Number). On les reconnaît à leur zone E remplie de 1, et leur
zone M non nulle.

#### Précision du codage

L'éventail des nombres réels que l'on peut coder ainsi est très large,
mais la précision n'est pas illimitée. On peut mesurer cette précision
en calculant l'écart qu'il y a entre le nombre 1.0 et le plus petit
nombre représentable qui lui soit immédiatement supérieur.

En représentation normalisée le nombre 1 s'écrit
$1.00\ldots \times 2^0$. Comme la zone M contient les 23 chiffres
"décimaux" de la mantisse, le nombre suivant s'obtient en remplaçant le
chiffre le plus à droite par un 1, ce qui correspond à $1+ 2^{-23}$. La
précision est donc de $2^{-23}$, soit à peu près $1.2 \times 10^{-7}$.
On compte donc, au mieux, sur 6 chiffres significatifs.

Attention, la précision se perd très rapidement lors des calculs
répétitifs, par exemple lors d'évaluation de séries de Taylor.

Pour avoir une meilleure précision on peut employer des nombres en
double précision, la mantisse occupant alors 32 bits supplémentaires.

Codage des caractères
---------------------

L'échange de données avec les périphériques d'entrée (clavier) et de
sortie (écran, imprimantes) se fait caractère par caractère. Dans les
premiers dispositifs utilisés (télétypes) les caractères étaient codés
sur 6 bits (26 lettres + 10 chiffres + 28 symboles). La distinction
entre majuscules et minuscules a exigé le passage à 7 bits (codes ASCII
et EBCDIC), et le passage à 8 bits est rendu nécessaire pour la
représentation des caractères accentués des langues européennes basées
sur l'alphabet romain (ISO 8859 Latin1). Il existe également un jeu de
caractères "universel" sur 32 bits appelé UNICODE, qui regroupe les
principaux alphabets utilisés dans le monde.

### Code ASCII 7 bits

Le code ASCII (American Standard Code for Information Interchange)
utilise une table de 128 positions, que l'on repère par leur numéro en
décimal. Si on met cette table sous forme de 8 colonnes, de 16 lignes,
les 2 premières colonnes contiennent des caractères dits "non
imprimables" suivis par des symboles divers. Les chiffres commencent en
quatrième colonne (position 48). Les majuscules sont en cinquième et
sixième colonne (à partir de 65), les minuscules dans les deux dernières
(à partir de 97).

En pratique les caractères ASCII sont transmis dans des octets, le bit
supplémentaire étant ignoré ou utilisé pour effectuer un *contrôle de
parité*:

-   bit de parité à 0: l'émetteur met 0 dans le bit de gauche. Si le
    récepteur y lit un 1, il y a eu une erreur de transmission.

-   bit de parité à 1 (semblable au précédent).

-   parité paire: l'émetteur met 0 ou 1 dans le bit de gauche de façon à
    ce que le nombre total de 1 dans l'octet soit pair. Si le récepteur
    reçoit un octet avec un nombre impair de 1, il y a eu une erreur.

-   parité impaire: comme ci-dessus.

Ce code suffit pour la langue anglaise, qui ignore les accents.

### Code EBCDIC

Autrefois préconisé par le principal constructeur d'ordinateurs de
l'époque (IBM). 

### Code ANSI/ISO Latin 8859-1

L'existence du marché européen a rendu nécessaire l'adoption de codes
contenant les lettres accentuées de l'alphabet latin. Divers codes 8
bits ont été utilisés, qui sont (à peu de choses près) des extensions du
code ASCII 7 bits : ASCII-IBM (pour les PC sous DOS), ANSI (PC sous
Windows), ASCII-McIntosh etc. Ces codes sont bien sûr incompatibles
entre eux.

En Europe de l'Ouest, où les caractères dérivent de l'alphabet romain,
on utilise le codage ISO (International Standard Organization)
8859-1.

### En attendant UNICODE\...

Le code 32 bits UNICODE permet de représenter
les alphabets les plus répandus (romain, cyrillique, arabe,
hébreu, grec, hiragana, katagana, coréen ...), mais pas pour les
idéogrammes chinois. 
